{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# seagliderOG1 demo\n",
    "\n",
    "The purpose of this notebook is to demonstrate the functionality of `seagliderOG1` to convert from Seaglider basestation files to OG1 format.\n",
    "\n",
    "- OG1 format is a newly agreed format (since June 2024) for glider data sets from various platforms (e.g., Seaglider, Slocum, Seaexplorer).  It lives on github here: (https://github.com/OceanGlidersCommunity/OG-format-user-manual).\n",
    "- OG1 manual: https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html\n",
    "\n",
    "The test case is to convert sg015 data from the Labrador Sea in September 2004.\n",
    "\n",
    "The demo is organised to show\n",
    "\n",
    "- Conversion of a single dive cycle (single `p*.nc` file)\n",
    "\n",
    "- Conversion for a folder of local dive-cycle files (full mission of `p*.nc` files)\n",
    "\n",
    "- Download from remote server + conversion (directory with full mission of `p*.nc` files)\n",
    "\n",
    "Options are provided to only load e.g. 10 files, but note that OG1 format expects a full mission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1920f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:44.182119Z",
     "iopub.status.busy": "2025-09-21T13:50:44.181904Z",
     "iopub.status.idle": "2025-09-21T13:50:46.535988Z",
     "shell.execute_reply": "2025-09-21T13:50:46.535402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/runner/work/seagliderOG1/seagliderOG1\n",
      "['/home/runner/micromamba/envs/TEST/lib/python313.zip', '/home/runner/micromamba/envs/TEST/lib/python3.13', '/home/runner/micromamba/envs/TEST/lib/python3.13/lib-dynload', '', '/home/runner/micromamba/envs/TEST/lib/python3.13/site-packages', '/home/runner/work/seagliderOG1/seagliderOG1', '/home/runner/work/seagliderOG1/seagliderOG1/seagliderOG1']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.io.formats' has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpooch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseagliderOG1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m readers, writers, plotters, tools\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseagliderOG1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convertOG1, vocabularies\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/seagliderOG1/seagliderOG1/seagliderOG1/plotters.py:18\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m##------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m## Views of the ds or nc file\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m##------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshow_contents\u001b[39m(data: \u001b[38;5;28mstr\u001b[39m | xr.Dataset, content_type: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformats\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m.Styler | pd.DataFrame:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Show contents of an xarray Dataset or a netCDF file.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    Wrapper function to display either variables or attributes from the dataset.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33;03m        If content_type is not 'variables', 'vars', 'attributes', or 'attrs'.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvars\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pandas.io.formats' has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "script_dir = pathlib.Path().parent.absolute()\n",
    "parent_dir = script_dir.parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "sys.path.append(str(parent_dir) + '/seagliderOG1')\n",
    "print(parent_dir)\n",
    "print(sys.path)\n",
    "### silence future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "import pooch\n",
    "from seagliderOG1 import readers, writers, plotters, tools\n",
    "from seagliderOG1 import convertOG1, vocabularies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e070d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.537848Z",
     "iopub.status.busy": "2025-09-21T13:50:46.537676Z",
     "iopub.status.idle": "2025-09-21T13:50:46.540171Z",
     "shell.execute_reply": "2025-09-21T13:50:46.539677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the path for writing datafiles\n",
    "data_path = os.path.join(parent_dir, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e373a",
   "metadata": {},
   "source": [
    "## Reading basestation files\n",
    "\n",
    "This has three ways to load a glider dataset.\n",
    "\n",
    "Load an example dataset using `seagliderOG1.fetchers.load_sample_dataset`\n",
    "\n",
    "Alternatively, use your own with e.g. `ds = xr.open_dataset('/path/to/yourfile.nc')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c414b4",
   "metadata": {},
   "source": [
    "### Load single sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ca56cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.541843Z",
     "iopub.status.busy": "2025-09-21T13:50:46.541680Z",
     "iopub.status.idle": "2025-09-21T13:50:46.557956Z",
     "shell.execute_reply": "2025-09-21T13:50:46.557536Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mreaders\u001b[49m.load_sample_dataset()\n\u001b[32m      2\u001b[39m ds\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "ds = readers.load_sample_dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1416e5",
   "metadata": {},
   "source": [
    "### Load datasets from a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83bba8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.559557Z",
     "iopub.status.busy": "2025-09-21T13:50:46.559383Z",
     "iopub.status.idle": "2025-09-21T13:50:46.581494Z",
     "shell.execute_reply": "2025-09-21T13:50:46.581058Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m input_dir = data_path + \u001b[33m'\u001b[39m\u001b[33m/demo_sg005\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m### chose the input directory with your data\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load and concatenate all datasets in the input directory\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Optionally, specify the range of profiles to load (start_profile, end_profile)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m list_datasets = \u001b[43mreaders\u001b[49m.load_basestation_files(input_dir, start_profile=\u001b[32m0\u001b[39m, end_profile=\u001b[32m5\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Where list_datasets is a list of xarray datasets.  A single dataset can be accessed as\u001b[39;00m\n\u001b[32m      9\u001b[39m ds = list_datasets[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = data_path + '/demo_sg005' ### chose the input directory with your data\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "list_datasets = readers.load_basestation_files(input_dir, start_profile=0, end_profile=5)\n",
    "\n",
    "# Where list_datasets is a list of xarray datasets.  A single dataset can be accessed as\n",
    "ds = list_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926863fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.582964Z",
     "iopub.status.busy": "2025-09-21T13:50:46.582815Z",
     "iopub.status.idle": "2025-09-21T13:50:46.598023Z",
     "shell.execute_reply": "2025-09-21T13:50:46.597482Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mreaders\u001b[49m.load_sample_dataset()\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "ds = readers.load_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4040443",
   "metadata": {},
   "source": [
    "### Load datasets from a remote directory (URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2913eb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.599650Z",
     "iopub.status.busy": "2025-09-21T13:50:46.599466Z",
     "iopub.status.idle": "2025-09-21T13:50:46.615739Z",
     "shell.execute_reply": "2025-09-21T13:50:46.615294Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m server = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m list_datasets = \u001b[43mreaders\u001b[49m.load_basestation_files(server, start_profile=\u001b[32m1\u001b[39m, end_profile=\u001b[32m10\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\"\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "list_datasets = readers.load_basestation_files(server, start_profile=1, end_profile=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4ebb6",
   "metadata": {},
   "source": [
    "## Convert to OG1 format\n",
    "\n",
    "Process:\n",
    "\n",
    "1. For one basestation dataset, split the dataset by dimension (`split_ds`)\n",
    "3. Transform into OG1 format: dataset with dims `sg_data_point`\n",
    "    - Change the dimension to `N_MEASUREMENTS`\n",
    "    - Rename variables according to `vocabularies.standard_names` \n",
    "    - Assign variable attributes according to `vocabularies.vocab_attrs`.  (Note: This *could* go wrong since it makes assumptions about the input variables. May need additional handling.)\n",
    "4. Add missing mandatory variables: \n",
    "    - From `split_ds[(gps_info,)]`, add the `LATITUDE_GPS`, `LONGITUDE_GPS` and `TIME_GPS` (Note: presently `TIME_GPS` is stripped before saving, but `TIME` values contain `TIME_GPS`)\n",
    "    - Create `PROFILE_NUMBER` and `PHASE`\n",
    "    - Calculate `DEPTH_Z` which is positive up\n",
    "5. Update attributes for the file. \n",
    "    - Combines `creator` and `contributor` from original attributes into `contributor`\n",
    "    - Adds `contributing_institutions` based on `institution`\n",
    "    - Reformats time in `time_coverage_*` and `start_time`--> `start_date`\n",
    "    - Adds `date_modified`\n",
    "    - Renames `comments`-->`history`, `site`-->`summary`\n",
    "    - Adds `title`, `platform`, `platform_vocabulary`, `featureType`, `Conventions`, `rtqc_method*` according to OceanGliders format\n",
    "    - Retains `naming_authority`, `institution`, `project`, `geospatial_*` as OG attributes\n",
    "    - Retains extra attributes: `license`, `keywords`, `keywords_vocabulary`, `file_version`, `acknowledgement`, `date_created`, `disclaimer`\n",
    "\n",
    "Future behaviour to be added:\n",
    "\n",
    "6. Retain the variables starting with `sg_cal` and check whether they vary over the mission (shouldn't)\n",
    "6. Add sensors, using information in the `split_ds` with no dimensions\n",
    "    - Need (from sg_cal_constants: `sg_cal` plus `volmax`, `vbd_cnts_per_cc`, `therm_expan`, `t_*`, `mass`, `hd_*`, `ctcor`, `cpcor`, `c_*`, `abs_compress`, `a`, `Tcor`, `Soc`, `Pcor`, `Foffset`)\n",
    "    - Maybe also `reviewed`, `magnetic_variation` (which will change with position), `log_D_FLARE`, `flight_avg_speed_north` and `flight_avg_speed_east` also with `_gsm`, `depth_avg_curr_north` and `depth_avg_curr_east` also with `_gsm`, \n",
    "    `wlbb2f` - means sensor\n",
    "    `sg_cal_mission_title`\n",
    "    `sg_cal_id_str`\n",
    "    `calibcomm_oxygen`\n",
    "    `calibcomm`\n",
    "    `sbe41` means ??\n",
    "    `hdm_qc`\n",
    "    `glider`\n",
    "    \n",
    "### Convert a single (sample) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd041858-c498-4654-a7c8-1731beb839fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.617233Z",
     "iopub.status.busy": "2025-09-21T13:50:46.617088Z",
     "iopub.status.idle": "2025-09-21T13:50:46.633063Z",
     "shell.execute_reply": "2025-09-21T13:50:46.632540Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loads one dataset (p0150500_20050213.nc)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds = \u001b[43mreaders\u001b[49m.load_sample_dataset()\n\u001b[32m      4\u001b[39m ds_OG1, var_list = convertOG1.convert_to_OG1(ds)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Check the results - uncomment the following lines to either generate a plot or show the variables.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "# Loads one dataset (p0150500_20050213.nc)\n",
    "ds = readers.load_sample_dataset()\n",
    "\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(ds)\n",
    "\n",
    "# Check the results - uncomment the following lines to either generate a plot or show the variables.\n",
    "plotters.plot_profile_depth(ds_OG1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b0e357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.634675Z",
     "iopub.status.busy": "2025-09-21T13:50:46.634489Z",
     "iopub.status.idle": "2025-09-21T13:50:46.649793Z",
     "shell.execute_reply": "2025-09-21T13:50:46.649332Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'var_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### print the list of inital variables of the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mvar_list\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'var_list' is not defined"
     ]
    }
   ],
   "source": [
    "### print the list of inital variables of the dataset\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b697a2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.651274Z",
     "iopub.status.busy": "2025-09-21T13:50:46.651115Z",
     "iopub.status.idle": "2025-09-21T13:50:46.666330Z",
     "shell.execute_reply": "2025-09-21T13:50:46.665827Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Print to screen a table of attributes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplotters\u001b[49m.show_contents(ds_OG1,\u001b[33m'\u001b[39m\u001b[33mattrs\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plotters' is not defined"
     ]
    }
   ],
   "source": [
    "# Print to screen a table of attributes\n",
    "plotters.show_contents(ds_OG1,'attrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c0c0ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.667857Z",
     "iopub.status.busy": "2025-09-21T13:50:46.667702Z",
     "iopub.status.idle": "2025-09-21T13:50:46.682887Z",
     "shell.execute_reply": "2025-09-21T13:50:46.682364Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Print to screen a table of the variables and variable attributes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplotters\u001b[49m.show_contents(ds_OG1,\u001b[33m'\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plotters' is not defined"
     ]
    }
   ],
   "source": [
    "# Print to screen a table of the variables and variable attributes\n",
    "plotters.show_contents(ds_OG1,'variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a27f3",
   "metadata": {},
   "source": [
    "### Convert mission from a local directory of basestation files\n",
    "\n",
    "- For local data in the directory `input_dir`\n",
    "- Creates a plot of ctd_depth against ctd_time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d202485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.684552Z",
     "iopub.status.busy": "2025-09-21T13:50:46.684366Z",
     "iopub.status.idle": "2025-09-21T13:50:46.701221Z",
     "shell.execute_reply": "2025-09-21T13:50:46.700724Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m input_dir = data_path + \u001b[33m'\u001b[39m\u001b[33m/demo_sg005\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m### chose the input directory with your data\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load and concatenate all datasets in the input directory\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Optionally, specify the range of profiles to load (start_profile, end_profile)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m list_datasets = \u001b[43mreaders\u001b[49m.load_basestation_files(input_dir, start_profile=\u001b[32m1\u001b[39m, end_profile=\u001b[32m5\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Convert the list of datasets to OG1\u001b[39;00m\n\u001b[32m      9\u001b[39m ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = data_path + '/demo_sg005' ### chose the input directory with your data\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "list_datasets = readers.load_basestation_files(input_dir, start_profile=1, end_profile=5)\n",
    "\n",
    "# Convert the list of datasets to OG1\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)\n",
    "\n",
    "# Generate a simple plot\n",
    "plotters.plot_profile_depth(ds_OG1)\n",
    "plotters.show_contents(ds_OG1,'attrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f9e81",
   "metadata": {},
   "source": [
    "### Convert mission from the NCEI server (with p*nc files)\n",
    "\n",
    "- Data from the sg015 mission in the Labrador Sea (https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:0111844), dataset identifier gov.noaa.nodc:0111844.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac290a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.702848Z",
     "iopub.status.busy": "2025-09-21T13:50:46.702690Z",
     "iopub.status.idle": "2025-09-21T13:50:46.718986Z",
     "shell.execute_reply": "2025-09-21T13:50:46.718563Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m server = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m list_datasets = \u001b[43mreaders\u001b[49m.load_basestation_files(server, start_profile=\u001b[32m1\u001b[39m, end_profile=\u001b[32m19\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Convert the list of datasets to OG1\u001b[39;00m\n\u001b[32m      8\u001b[39m ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)\n",
      "\u001b[31mNameError\u001b[39m: name 'readers' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\"\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "list_datasets = readers.load_basestation_files(server, start_profile=1, end_profile=19)\n",
    "\n",
    "# Convert the list of datasets to OG1\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baa613",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "\n",
    "Due to problems with writing `xarray` datasets as netCDF when attributes are not of a specified type (`str`, `Number`, `np.ndarray`, `np.number`, `list`, `tuple`), a function was written `save_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3540ad10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.720506Z",
     "iopub.status.busy": "2025-09-21T13:50:46.720359Z",
     "iopub.status.idle": "2025-09-21T13:50:46.737349Z",
     "shell.execute_reply": "2025-09-21T13:50:46.736795Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(output_file):\n\u001b[32m      6\u001b[39m     os.remove(output_file)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mwriters\u001b[49m.save_dataset(ds_OG1, output_file);\n",
      "\u001b[31mNameError\u001b[39m: name 'writers' is not defined"
     ]
    }
   ],
   "source": [
    "# Write the file\n",
    "# This writer catches errors in data types (DType errors) when using xr.to_netcdf()\n",
    "# The solution is to convert them to strings, which may be undesired behaviour\n",
    "output_file = os.path.join(data_path, 'demo_test.nc')\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "writers.save_dataset(ds_OG1, output_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57da6f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.738925Z",
     "iopub.status.busy": "2025-09-21T13:50:46.738767Z",
     "iopub.status.idle": "2025-09-21T13:50:46.961453Z",
     "shell.execute_reply": "2025-09-21T13:50:46.960889Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/runner/work/seagliderOG1/seagliderOG1/data/demo_test.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/file_manager.py:211\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/lru_cache.py:56\u001b[39m, in \u001b[36mLRUCache.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache.move_to_end(key)\n",
      "\u001b[31mKeyError\u001b[39m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/runner/work/seagliderOG1/seagliderOG1/data/demo_test.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'c3e9d6a1-efd5-4737-8e1e-4b128aa9fa64']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the data saved\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds1 = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Generate a simple plot\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#plotters.show_contents(ds_all,'attrs')\u001b[39;00m\n\u001b[32m      6\u001b[39m plotters.plot_depth_colored(ds1, color_by=\u001b[33m'\u001b[39m\u001b[33mPROFILE_NUMBER\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/api.py:760\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, create_default_indexes, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m decoders = _resolve_decoders_kwargs(\n\u001b[32m    749\u001b[39m     decode_cf,\n\u001b[32m    750\u001b[39m     open_backend_dataset_parameters=backend.open_dataset_parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m     decode_coords=decode_coords,\n\u001b[32m    757\u001b[39m )\n\u001b[32m    759\u001b[39m overwrite_encoded_chunks = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33moverwrite_encoded_chunks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m backend_ds = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m ds = _dataset_from_backend_dataset(\n\u001b[32m    767\u001b[39m     backend_ds,\n\u001b[32m    768\u001b[39m     filename_or_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    779\u001b[39m     **kwargs,\n\u001b[32m    780\u001b[39m )\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:682\u001b[39m, in \u001b[36mNetCDF4BackendEntrypoint.open_dataset\u001b[39m\u001b[34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, auto_complex, lock, autoclose)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_dataset\u001b[39m(\n\u001b[32m    661\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    662\u001b[39m     filename_or_obj: T_PathFileOrDataStore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    679\u001b[39m     autoclose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    680\u001b[39m ) -> Dataset:\n\u001b[32m    681\u001b[39m     filename_or_obj = _normalize_path(filename_or_obj)\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     store = \u001b[43mNetCDF4DataStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m     store_entrypoint = StoreBackendEntrypoint()\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:468\u001b[39m, in \u001b[36mNetCDF4DataStore.open\u001b[39m\u001b[34m(cls, filename, mode, format, group, clobber, diskless, persist, auto_complex, lock, lock_maker, autoclose)\u001b[39m\n\u001b[32m    464\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauto_complex\u001b[39m\u001b[33m\"\u001b[39m] = auto_complex\n\u001b[32m    465\u001b[39m manager = CachingFileManager(\n\u001b[32m    466\u001b[39m     netCDF4.Dataset, filename, mode=mode, kwargs=kwargs\n\u001b[32m    467\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:398\u001b[39m, in \u001b[36mNetCDF4DataStore.__init__\u001b[39m\u001b[34m(self, manager, group, mode, lock, autoclose)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28mself\u001b[39m._group = group\n\u001b[32m    397\u001b[39m \u001b[38;5;28mself\u001b[39m._mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m \u001b[38;5;28mself\u001b[39m.format = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mds\u001b[49m.data_model\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._filename = \u001b[38;5;28mself\u001b[39m.ds.filepath()\n\u001b[32m    400\u001b[39m \u001b[38;5;28mself\u001b[39m.is_remote = is_remote_uri(\u001b[38;5;28mself\u001b[39m._filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:477\u001b[39m, in \u001b[36mNetCDF4DataStore.ds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:471\u001b[39m, in \u001b[36mNetCDF4DataStore._acquire\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/file_manager.py:199\u001b[39m, in \u001b[36mCachingFileManager.acquire_context\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    198\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     file, cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/TEST/lib/python3.13/site-packages/xarray/backends/file_manager.py:217\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    215\u001b[39m     kwargs = kwargs.copy()\n\u001b[32m    216\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._mode\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode == \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28mself\u001b[39m._mode = \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/runner/work/seagliderOG1/seagliderOG1/data/demo_test.nc'"
     ]
    }
   ],
   "source": [
    "# Load the data saved\n",
    "ds1 = xr.open_dataset(output_file)\n",
    "\n",
    "# Generate a simple plot\n",
    "#plotters.show_contents(ds_all,'attrs')\n",
    "plotters.plot_depth_colored(ds1, color_by='PROFILE_NUMBER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaed738",
   "metadata": {},
   "source": [
    "## Run multiple missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12f47f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.963276Z",
     "iopub.status.busy": "2025-09-21T13:50:46.963110Z",
     "iopub.status.idle": "2025-09-21T13:50:46.982887Z",
     "shell.execute_reply": "2025-09-21T13:50:46.982479Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabularies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add these to existing attributes - update to your details\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m contrib_to_append = \u001b[43mvocabularies\u001b[49m.contrib_to_append\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(contrib_to_append)\n",
      "\u001b[31mNameError\u001b[39m: name 'vocabularies' is not defined"
     ]
    }
   ],
   "source": [
    "# Add these to existing attributes - update to your details\n",
    "contrib_to_append = vocabularies.contrib_to_append\n",
    "print(contrib_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6127a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T13:50:46.984346Z",
     "iopub.status.busy": "2025-09-21T13:50:46.984190Z",
     "iopub.status.idle": "2025-09-21T13:50:47.001885Z",
     "shell.execute_reply": "2025-09-21T13:50:47.001374Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convertOG1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m      2\u001b[39m input_locations = [\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Either Iceland, Faroes or RAPID/MOCHA\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m#\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20090829/\", # done\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m#\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/034/20110128/\",\u001b[39;00m\n\u001b[32m     29\u001b[39m ]\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_loc \u001b[38;5;129;01min\u001b[39;00m input_locations:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     ds_all = \u001b[43mconvertOG1\u001b[49m.process_and_save_data(input_loc, output_dir=data_path, save=\u001b[38;5;28;01mTrue\u001b[39;00m,  run_quietly=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'convertOG1' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify a list of servers or local directories\n",
    "input_locations = [\n",
    "    # Either Iceland, Faroes or RAPID/MOCHA\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20090829/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20080606/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20081106/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/012/20070831/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080214/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080222/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20061112/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20090605/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20071113/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20080607/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100518/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20081108/\",     # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20061112/\",    # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20070609/\",   # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/102/20061112/\",  # done\n",
    "    # Labrador Sea\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20040924/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/008/20031002/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/004/20031002/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20050406/\",\n",
    "    # RAPID/MOCHA\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100729/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/034/20110128/\",\n",
    "]\n",
    "\n",
    "for input_loc in input_locations:\n",
    "    # Example usage\n",
    "    ds_all = convertOG1.process_and_save_data(input_loc, output_dir=data_path, save=True,  run_quietly=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
